# OpenAI API Configuration
# Copy this file to .env and add your actual API key
# Get your API key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Local LLM Configuration (Ollama)
# Model to use for PII detection (e.g., llama3.1:8b, mistral:latest, llama3:latest)
# List your models with: ollama list
OLLAMA_MODEL=llama3.1:8b

# Ollama API endpoint (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434
